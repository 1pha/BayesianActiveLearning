{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\bnn\\lib\\site-packages\\torch\\cuda\\__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "from dataset import build_dataset\n",
    "from config import DataArguments, TrainerArguments, ModelArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/20/2021 18:56:07] INFO - dataloader: Initialize Train Dataset.\n",
      "[11/20/2021 18:56:07] INFO - dataloader: Remove abstract.\n",
      "[11/20/2021 18:56:07] INFO - dataloader: Remove task_id\n",
      "[11/20/2021 18:56:07] INFO - dataloader: Use 0.05% of the total dataset.\n",
      "[11/20/2021 18:56:08] INFO - dataloader: Total 2363 of papers will be used.\n",
      "[11/20/2021 18:56:10] INFO - preprocess: Successfully loaded Spacy Tokenizer, en_core_web_trf\n",
      "[11/20/2021 18:56:10] INFO - dataloader: Successfully loaded mapper file ..\\assets\\area2idx.json\n",
      "[11/20/2021 18:56:10] INFO - dataloader: Train dataset was successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "data_args = DataArguments\n",
    "training_args = TrainerArguments\n",
    "model_args = ModelArguments\n",
    "\n",
    "data_args.data_dir = \"../data/\"\n",
    "data_args.seed = training_args.seed\n",
    "data_args.max_seq_len = model_args.max_seq_len\n",
    "\n",
    "dataset = build_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tokenize = dataset.preprocessor.tokenize\n",
    "def encode(example):\n",
    "    \n",
    "    input_raw = example[\"title\"] if \"abstract\" not in example else f\"{example['title']}[SEP]{example['abstract']}\"\n",
    "    input_ids = tokenize(input_raw).squeeze()\n",
    "    label = torch.tensor(dataset.area2idx[example[\"area\"]], dtype=torch.long)\n",
    "\n",
    "    seq_len = len(input_ids)\n",
    "    if seq_len > data_args.max_seq_len:\n",
    "        input_ids = input_ids[:data_args.max_seq_len]\n",
    "        seq_len = data_args.max_seq_len\n",
    "    else:\n",
    "        zero_seq = torch.zeros(data_args.max_seq_len)\n",
    "        zero_seq[:seq_len] = input_ids\n",
    "        input_ids, zero_seq = zero_seq, input_ids\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"label\": label,\n",
    "        \"seq_len\": torch.tensor(seq_len, dtype=torch.long)\n",
    "    }\n",
    "\n",
    "def batch_encode(example):\n",
    "    \n",
    "    input_raw = example[\"title\"] if \"abstract\" not in example else f\"{example['title']}[SEP]{example['abstract']}\"\n",
    "    input_ids = tokenize(input_raw)\n",
    "    label = [dataset.area2idx[area] for area in example[\"area\"]]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"label\": label,\n",
    "        \"seq_len\": [len(i) for i in input_ids]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/20/2021 18:56:13] WARNING - datasets.fingerprint: Parameter 'function'=<function batch_encode at 0x00000211772D5828> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "  0%|          | 0/3 [00:00<?, ?ba/s]C:\\Users\\pha\\anaconda3\\envs\\bnn\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "100%|██████████| 3/3 [01:29<00:00, 29.85s/ba]\n"
     ]
    }
   ],
   "source": [
    "hf_dataset = dataset.dataset.map(batch_encode, batched=True, remove_columns=[\"area\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'label', 'seq_len'],\n",
       "    num_rows: 2363\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?ba/s]C:\\Users\\pha\\anaconda3\\envs\\bnn\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "100%|██████████| 3/3 [01:31<00:00, 30.40s/ba]\n"
     ]
    }
   ],
   "source": [
    "def batch_encode(example):\n",
    "    \n",
    "    input_raw = example[\"title\"] if \"abstract\" not in example else f\"{example['title']}[SEP]{example['abstract']}\"\n",
    "    input_ids = tokenize(input_raw)\n",
    "    label = [dataset.area2idx[area] for area in example[\"area\"]]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"label\": label,\n",
    "        # \"seq_len\": [len(i) for i in input_ids]\n",
    "    }\n",
    "    \n",
    "hf_dataset = dataset.dataset.map(batch_encode, batched=True, remove_columns=[\"area\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\bnn\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  45681,\n",
       "  5206,\n",
       "  45998,\n",
       "  3870,\n",
       "  10845,\n",
       "  11,\n",
       "  11202,\n",
       "  26970,\n",
       "  21888,\n",
       "  8250,\n",
       "  10244,\n",
       "  19,\n",
       "  26056,\n",
       "  7590,\n",
       "  14641,\n",
       "  2]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tokenize(dataset.dataset[10][\"title\"]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\bnn\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 35166,\n",
       " 17789,\n",
       " 46637,\n",
       " 13807,\n",
       " 13,\n",
       " 19268,\n",
       " 12,\n",
       " 46022,\n",
       " 16730,\n",
       " 29517,\n",
       " 154,\n",
       " 8,\n",
       " 2825,\n",
       " 21553,\n",
       " 154,\n",
       " 26283,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100][\"input_ids\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\bnn\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 16134, 16134,     2]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"dddd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(dataset.dataset[998\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\bnn\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,   500,  4774,  ...,     0,     0,     0],\n",
       "         [    0,  9685, 16101,  ...,     0,     0,     0],\n",
       "         [    0, 48730,     9,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    0, 46064,    12,  ...,     0,     0,     0],\n",
       "         [    0, 48739,    12,  ...,     0,     0,     0],\n",
       "         [    0, 43597, 42312,  ...,     0,     0,     0]]),\n",
       " 'labels': tensor([11,  7, 15,  4, 15, 10,  7,  6, 14, 14, 12,  7,  7, 10, 15,  7, 10, 14,\n",
       "         10, 10,  7,  6, 13, 11,  7, 12,  7,  4,  4,  7, 15, 15,  4,  0, 12,  3,\n",
       "         12,  3, 15,  3, 13,  3, 15,  3, 10, 11,  4,  4, 10,  7,  7,  7,  2,  3,\n",
       "         10,  7,  3,  7,  7, 10, 12,  3, 15, 15,  4,  7, 15,  3, 12, 15, 10, 14,\n",
       "         12,  4, 14, 12, 10,  3, 14,  7, 15,  2,  8,  0, 12,  4, 10, 14,  7, 15,\n",
       "         10, 10, 14,  7, 10, 12,  3, 14,  3, 15, 15,  0,  3,  7, 11, 14, 14, 12,\n",
       "         14, 13, 12,  7, 10, 15, 10,  3, 10,  5, 12,  5,  3, 15,  7, 10, 14, 15,\n",
       "         14,  3]),\n",
       " 'seq_len': tensor([ 8, 20, 25, 12, 18, 15, 20, 23, 21, 28, 12, 12, 14, 21, 14, 11, 16, 20,\n",
       "         16, 20, 19, 20, 22, 19, 13, 19, 16, 10, 11, 15, 18, 17, 12, 19, 23, 16,\n",
       "         14, 20, 19, 19, 14, 17, 14, 16, 24, 13, 11, 14, 16,  9, 20,  9, 16, 11,\n",
       "         10, 15,  5,  9, 17, 15, 17, 17, 14, 15,  9, 17, 21, 19, 14, 23, 21, 20,\n",
       "         17, 14, 20, 18, 22, 23, 14,  9, 22, 10, 10, 24, 19, 11, 12, 11, 15, 17,\n",
       "         19, 13, 13, 27, 24, 16, 11, 15, 17, 12, 12, 17, 18, 29, 14, 24, 13, 11,\n",
       "          8, 19, 33, 10, 14, 16, 22, 13, 17, 12, 15, 22, 14, 17, 18, 10, 21, 22,\n",
       "         18, 25])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\bnn\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.vstack((dataset[0][\"input_ids\"], dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = BertConfig(\n",
    "    vocab_size=len(nlp.vocab.strings)\n",
    ")\n",
    "model = BertForSequenceClassification(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\bnn\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.1435, -0.0564]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids=dataset[0][\"input_ids\"].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = model(input_ids=dataset[0][\"input_ids\"].unsqueeze(0))[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1429,  0.0209]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_seq[0]dd[:seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token_seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11352/880449891.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtoken_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'token_seq' is not defined"
     ]
    }
   ],
   "source": [
    "token_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\envs\\bnn\\lib\\site-packages\\torch\\cuda\\__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "C:\\Users\\pha\\anaconda3\\envs\\bnn\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "documents = \"Spacy sucks. Nothing is being donwloaded.\"\n",
    "\n",
    "tokenizer = spacy.load(\"en_core_web_trf\")\n",
    "doc = tokenizer(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc._.trf_data.tokens[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a61f66c06004f41873e28d463485a6c1d6ba80ac66cbf9cb782a5e0aa1d62397"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('bnn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
