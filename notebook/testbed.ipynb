{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "from dataset import build_dataset, build_dataloader\n",
    "from config import DataArguments, TrainerArguments, ModelArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/24/2021 20:59:19] INFO - dataset: Initialize Train Dataset.\n",
      "[11/24/2021 20:59:19] INFO - dataset: Remove abstract.\n",
      "[11/24/2021 20:59:19] INFO - dataset: Using cached dataset, wasn't able to remove columns.\n",
      "[11/24/2021 20:59:19] INFO - dataset: Use the full dataset, for train dataset of total 47250 papers.\n",
      "[11/24/2021 20:59:19] INFO - dataset: Train dataset was successfully initialized.\n",
      "[11/24/2021 20:59:19] INFO - dataset: Successfully loaded mapper file ..\\assets\\area2idx.json\n",
      "[11/24/2021 20:59:19] INFO - dataset: Use tokenized_paperswithcode dataset.\n",
      "[11/24/2021 20:59:19] INFO - dataset: Preprocessed dataset. Use default vocab_size=83931.\n",
      "[11/24/2021 20:59:19] INFO - dataset: Successfully converted dataset to dataloader.\n"
     ]
    }
   ],
   "source": [
    "data_args = DataArguments()\n",
    "training_args = TrainerArguments()\n",
    "model_args = ModelArguments()\n",
    "\n",
    "data_args.data_dir = \"../data/\"\n",
    "data_args.asset_dir = \"../assets/\"\n",
    "model_args.asset_dir = data_args.asset_dir\n",
    "data_args.seed = training_args.seed\n",
    "data_args.max_seq_len = model_args.max_seq_len\n",
    "\n",
    "data_args.init_pct = 1\n",
    "training_args.do_train = True\n",
    "training_args.use_gpu = False\n",
    "\n",
    "pool_dataset, train_dataset, model_args.vocab_size, model_args.num_labels = build_dataset(data_args, \"train\")\n",
    "train_dataloader = build_dataloader(train_dataset, data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/24/2021 16:55:46] INFO - trainer: Bert was selected. Start Transformer setup.\n",
      "[11/24/2021 16:55:46] INFO - trainer: Successfully setup transformer settings.\n"
     ]
    }
   ],
   "source": [
    "from trainer import NaiveTrainer\n",
    "trainer= NaiveTrainer(\n",
    "    data_args,\n",
    "    training_args,\n",
    "    model_args,\n",
    "    training_dataset=train_dataloader if training_args.do_train else None,\n",
    "    validation_dataset=valid_dataloader if training_args.do_valid else None,\n",
    "    test_dataset=test_dataloader if training_args.do_test else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 14])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_dataset[0, 4][\"input_ids\"] == 2).nonzero()[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "trainer.model.load_state_dict(torch.load(\"../output/BERT (1)/checkpoints/099.pt\"))\n",
    "# trainer.model.load_state_dict(torch.load(\"../output/BERT_BCE (4)/checkpoints/014.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from toma import toma\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from batchbald_redux import joint_entropy\n",
    "\n",
    "K = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_mixture_prob_dist(p1, p2, m):\n",
    "    return (1.0 - m) * np.asarray(p1) + m * np.asarray(p2)\n",
    "\n",
    "\n",
    "p1 = [0.7, 0.1, 0.1, 0.1]\n",
    "p2 = [0.3, 0.3, 0.2, 0.2]\n",
    "y1_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.7, 0.1, 0.1]\n",
    "p2 = [0.2, 0.3, 0.3, 0.2]\n",
    "y2_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.7, 0.1]\n",
    "p2 = [0.2, 0.2, 0.3, 0.3]\n",
    "y3_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.1, 0.7]\n",
    "p2 = [0.3, 0.2, 0.2, 0.3]\n",
    "y4_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "\n",
    "def nested_to_tensor(l):\n",
    "    return torch.stack(list(map(torch.as_tensor, l)))\n",
    "\n",
    "\n",
    "ys_ws = nested_to_tensor([y1_ws, y2_ws, y3_ws, y4_ws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7000, 0.1000, 0.1000, 0.1000],\n",
       "         [0.6789, 0.1105, 0.1053, 0.1053],\n",
       "         [0.6579, 0.1211, 0.1105, 0.1105],\n",
       "         [0.6368, 0.1316, 0.1158, 0.1158],\n",
       "         [0.6158, 0.1421, 0.1211, 0.1211],\n",
       "         [0.5947, 0.1526, 0.1263, 0.1263],\n",
       "         [0.5737, 0.1632, 0.1316, 0.1316],\n",
       "         [0.5526, 0.1737, 0.1368, 0.1368],\n",
       "         [0.5316, 0.1842, 0.1421, 0.1421],\n",
       "         [0.5105, 0.1947, 0.1474, 0.1474],\n",
       "         [0.4895, 0.2053, 0.1526, 0.1526],\n",
       "         [0.4684, 0.2158, 0.1579, 0.1579],\n",
       "         [0.4474, 0.2263, 0.1632, 0.1632],\n",
       "         [0.4263, 0.2368, 0.1684, 0.1684],\n",
       "         [0.4053, 0.2474, 0.1737, 0.1737],\n",
       "         [0.3842, 0.2579, 0.1789, 0.1789],\n",
       "         [0.3632, 0.2684, 0.1842, 0.1842],\n",
       "         [0.3421, 0.2789, 0.1895, 0.1895],\n",
       "         [0.3211, 0.2895, 0.1947, 0.1947],\n",
       "         [0.3000, 0.3000, 0.2000, 0.2000]],\n",
       "\n",
       "        [[0.1000, 0.7000, 0.1000, 0.1000],\n",
       "         [0.1053, 0.6789, 0.1105, 0.1053],\n",
       "         [0.1105, 0.6579, 0.1211, 0.1105],\n",
       "         [0.1158, 0.6368, 0.1316, 0.1158],\n",
       "         [0.1211, 0.6158, 0.1421, 0.1211],\n",
       "         [0.1263, 0.5947, 0.1526, 0.1263],\n",
       "         [0.1316, 0.5737, 0.1632, 0.1316],\n",
       "         [0.1368, 0.5526, 0.1737, 0.1368],\n",
       "         [0.1421, 0.5316, 0.1842, 0.1421],\n",
       "         [0.1474, 0.5105, 0.1947, 0.1474],\n",
       "         [0.1526, 0.4895, 0.2053, 0.1526],\n",
       "         [0.1579, 0.4684, 0.2158, 0.1579],\n",
       "         [0.1632, 0.4474, 0.2263, 0.1632],\n",
       "         [0.1684, 0.4263, 0.2368, 0.1684],\n",
       "         [0.1737, 0.4053, 0.2474, 0.1737],\n",
       "         [0.1789, 0.3842, 0.2579, 0.1789],\n",
       "         [0.1842, 0.3632, 0.2684, 0.1842],\n",
       "         [0.1895, 0.3421, 0.2789, 0.1895],\n",
       "         [0.1947, 0.3211, 0.2895, 0.1947],\n",
       "         [0.2000, 0.3000, 0.3000, 0.2000]],\n",
       "\n",
       "        [[0.1000, 0.1000, 0.7000, 0.1000],\n",
       "         [0.1053, 0.1053, 0.6789, 0.1105],\n",
       "         [0.1105, 0.1105, 0.6579, 0.1211],\n",
       "         [0.1158, 0.1158, 0.6368, 0.1316],\n",
       "         [0.1211, 0.1211, 0.6158, 0.1421],\n",
       "         [0.1263, 0.1263, 0.5947, 0.1526],\n",
       "         [0.1316, 0.1316, 0.5737, 0.1632],\n",
       "         [0.1368, 0.1368, 0.5526, 0.1737],\n",
       "         [0.1421, 0.1421, 0.5316, 0.1842],\n",
       "         [0.1474, 0.1474, 0.5105, 0.1947],\n",
       "         [0.1526, 0.1526, 0.4895, 0.2053],\n",
       "         [0.1579, 0.1579, 0.4684, 0.2158],\n",
       "         [0.1632, 0.1632, 0.4474, 0.2263],\n",
       "         [0.1684, 0.1684, 0.4263, 0.2368],\n",
       "         [0.1737, 0.1737, 0.4053, 0.2474],\n",
       "         [0.1789, 0.1789, 0.3842, 0.2579],\n",
       "         [0.1842, 0.1842, 0.3632, 0.2684],\n",
       "         [0.1895, 0.1895, 0.3421, 0.2789],\n",
       "         [0.1947, 0.1947, 0.3211, 0.2895],\n",
       "         [0.2000, 0.2000, 0.3000, 0.3000]],\n",
       "\n",
       "        [[0.1000, 0.1000, 0.1000, 0.7000],\n",
       "         [0.1105, 0.1053, 0.1053, 0.6789],\n",
       "         [0.1211, 0.1105, 0.1105, 0.6579],\n",
       "         [0.1316, 0.1158, 0.1158, 0.6368],\n",
       "         [0.1421, 0.1211, 0.1211, 0.6158],\n",
       "         [0.1526, 0.1263, 0.1263, 0.5947],\n",
       "         [0.1632, 0.1316, 0.1316, 0.5737],\n",
       "         [0.1737, 0.1368, 0.1368, 0.5526],\n",
       "         [0.1842, 0.1421, 0.1421, 0.5316],\n",
       "         [0.1947, 0.1474, 0.1474, 0.5105],\n",
       "         [0.2053, 0.1526, 0.1526, 0.4895],\n",
       "         [0.2158, 0.1579, 0.1579, 0.4684],\n",
       "         [0.2263, 0.1632, 0.1632, 0.4474],\n",
       "         [0.2368, 0.1684, 0.1684, 0.4263],\n",
       "         [0.2474, 0.1737, 0.1737, 0.4053],\n",
       "         [0.2579, 0.1789, 0.1789, 0.3842],\n",
       "         [0.2684, 0.1842, 0.1842, 0.3632],\n",
       "         [0.2789, 0.1895, 0.1895, 0.3421],\n",
       "         [0.2895, 0.1947, 0.1947, 0.3211],\n",
       "         [0.3000, 0.2000, 0.2000, 0.3000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_2d(logits):\n",
    "\n",
    "    if logits.ndim == 3 and logits.shape[1] == 1:\n",
    "        logits = logits.squeeze()\n",
    "        return logits\n",
    "    elif logits.ndim == 3 and logits.shape[1] > 1:\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "p1 = [0.7, 0.1, 0.1, 0.1, 0.0]\n",
    "p2 = [0.3, 0.3, 0.2, 0.2, 0.0]\n",
    "\n",
    "logits = torch.stack(tuple(map(torch.tensor, (p1, p2)))).unsqueeze(1)\n",
    "logits_np = np.array((p1, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acquisition_function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = []\n",
    "lst.append(margin_of_confidence(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 1, 3]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(lst).argsort().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = torch.split(-_logits, 1, dim=1)[0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7000, -0.3000])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1000, -0.3000])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_logit = logits.squeeze().sort(dim=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acquisition_function import margin_of_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6000, 0.0000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin_of_confidence(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47250"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[:50000][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a61f66c06004f41873e28d463485a6c1d6ba80ac66cbf9cb782a5e0aa1d62397"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('bnn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
